# LinkSeq Phase -- Multi-sample linked-read phasing [WIP]

**NOTE:** This pipeline is a work-in-progress and should not be used as is.

[![Docker build](https://img.shields.io/badge/Docker%20build-Available-informational)](https://hub.docker.com/repository/docker/fargen/linkseq-phase)

This pipeline uses [HapCUT2](https://github.com/vibansal/HapCUT2) to phase the haplotypes in a multi-sample linked-read VCF.

The pipeline expects the input data to be generated by the [LinkSeq](https://github.com/fargenfo/linkseq) and [gatk-joint-genotyping](https://github.com/fargenfo/gatk-joint-genotyping) pipelines. More generally, the pipeline requires a multi-sample VCF file and BAM files for each sample generated by a linked-read aware aligner ([EMA](https://github.com/arshajii/ema/) or [Lariat](https://support.10xgenomics.com/genome-exome/software/pipelines/latest/what-is-long-ranger)).

This pipeline makes little sense outside of the context of LinkSeq, so for more information see the [LinkSeq documentation](https://github.com/fargenfo/linkseq).

The main steps in the pipeline are the following:

* Split the multi-sample VCF into single-sample VCFs
* Remove the PL and PP fields from the VCF
* Remove no-call sites
* Phase the single-sample VCFs using HapCUT2
* Merge phased VCFs into a multi-sample VCF
* Calculate phasing stats

## Setup

**NOTE:** at the moment it is advised to only use the [fargenfo/linkseq-phase](https://hub.docker.com/repository/docker/fargenfo/linkseq-phase) Docker image to run the pipeline. The current HapCUT2 conda package is broken, and until a newer one is released (>1.3.2) the only option is to build the latest HapCUT2 commit from source. **TL;DR just use the Docker image and ignore the instructions in this section**.

Install dependencies with `conda` using the `environment.yml` file:

```
conda env create -f environment.yml
```

Activate the environment (check the name of the environment in the `environment.yml` file, it should be `linkseq-phase`):

```
conda activate linkseq-phase
```

Pull this project with `nextflow`:

```
nextflow pull https://github.com/fargenfo/linkseq-phase
```

## Usage


Below is an example config file for Nextflow.

```nextflow
params {
    bam_paths = '/path/to/bam_lis.csv'
    vcf = '/path/to/multi_sample.vcf'
    reference = '/path/to/reference.fasta'
    outdir = 'outs'
}

process {
    executor = 'local'
    memory = '10GB'
    cpus = 1
    // The merging process gets a lot of resources
    // NOTE: I'm not 100% sure this process does any multi-processing work or if it has use for a lot of memory.
    withName: merge_phased_vcf {
        executor = 'local'
        memory = '100GB'
        cpus = 10
    }
}

executor {
    name = 'local'
    memory = '100GB'
    cpus = 10
    queueSize = 100
}

// Capture exit codes from upstream processes when piping.
process.shell = ['/bin/bash', '-euo', 'pipefail']
```

The `samples.tsv` file will have sample names and paths to GVCF files, and will look something like this:

```csv
sample,bam_path,bai_path
sample1,/path/to/sample1.bam,/path/to/sample1.bai
sample2,/path/to/sample2.bam,/path/to/sample2.bai
sample3,/path/to/sample3.bam,/path/to/sample3.bai
```

Run the pipeline with this command:

```bash
nextflow run fargenfo/linkseq-phase -resume -with-trace
```

The output of the pipeline is as follows (summarized by the `tree outs/` command):

```
outs/
├── phased_merged.vcf.gz
├── phased_merged.vcf.gz.tbi
└── phasing_stats
    ├── sample1
    │   ├── phase_blocks.gtf
    │   └── phasing_stats.tsv
    ├── sample2
    │   ├── phase_blocks.gtf
    │   └── phasing_stats.tsv
    ├── sample3
    │   ├── phase_blocks.gtf
    │   └── phasing_stats.tsv
```

## Resources

Information about how to obtain the reference data can be found in the LinkSeq documentation: https://github.com/fargenfo/linkseq#reference-resources

